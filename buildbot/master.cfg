####### -*- python -*-
# ex: set syntax=python:
# vim:ft=python

# This is a buildmaster config file. It must be installed as
# 'master.cfg' in your buildmaster's base directory.

import datetime
from itertools import ifilter, imap
import json
import os
import re
import subprocess

from buildbot.plugins import buildslave, changes, schedulers, status, steps, util
# In 0.8.12, WebStatus can't be used as a plugin because it doesn't
# actually implement the IStatusReceiver interface, as it claims to.
from buildbot.status.web.baseweb import WebStatus
from twisted.internet import defer

####### HELPER FUNCTIONS #######

def _path(name):
    return os.path.join(os.path.dirname(__file__), name)

def merge_dicts(*dicts):
    res = {}
    for d in dicts:
        res.update(d)
    return res

def port_from_path(path, sep='/'):
    components = path.split(sep)
    try:
        if (components[0] == 'dports' and components[1] != '_resources'
                and components[3] in ('Portfile', 'files')):
            return components[2]
    except IndexError:
        pass
    # Might be better to throw a custom exception here?
    return None


# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Master variable to toggle config between testing on your personal system
# (where /opt/local shouldn't be messed with) and the production server (where
# it has to be)

config = {
    'production': False,
    'privkey': '',
    'slaveport': 9989,
    'httpport': 8010,
    'buildboturl': 'http://localhost:8010/',
    'htpasswdfile': 'htpasswd',
    'mpbbsvnurl': 'https://svn.macports.org/repository/macports/contrib/mp-buildbot',
    'svnurl': 'https://svn.macports.org/repository/macports/trunk',
    'archivesite': 'https://packages.macports.org',
    'slaveprefix': '/opt/local',
    'toolsprefix': '/opt/mports',
    'deploy': {}
    }

if os.path.exists(_path('config.json')):
    with open(_path('config.json')) as f:
        configdata = json.load(f)
    config.update(configdata)

path_base = '/usr/bin:/bin:/usr/sbin:/sbin'
path_ports = os.path.join(config['toolsprefix'], 'bin') + ':' + path_base
path_docs = path_ports

# Allow spaces and tabs in property values
c['validation'] = {'property_value': re.compile(r'^[ \t\w./~:-]*$')}


####### BUILDSLAVES #######

# The 'slaves' list defines the set of recognized buildslaves. Each element is
# a BuildSlave object, specifying a unique slave name and password.  The same
# slave name and password must be configured on the slave.

with open(_path('slaves.json')) as f:
    slavedata = json.load(f)

# convert unicode to byte strings
build_platforms = [s.encode('utf-8') for s in slavedata['build_platforms']]

c['slaves'] = [buildslave.BuildSlave(name, pwd)
               for name, pwd in slavedata['slaves'].iteritems()]

# 'slavePortnum' defines the TCP port to listen on for connections from slaves.
# This must match the value configured into the buildslaves (with their
# --master option)
c['slavePortnum'] = config['slaveport']


####### CHANGESOURCES #######

# the 'change_source' setting tells the buildmaster how it should find out
# about source code changes.

# poller is used for local testing but PBChangeSource (which relies on
# notifications from a post-commit script) should be used in production

if config['production']:
    # TODO
    sourcedata = []
#    with open(_path('source.json')) as f:
#        sourcedata = json.load(f)
#    c['change_source'] = changes.PBChangeSource(user=sourcedata[0], passwd=sourcedata[1], port=sourcedata[2])
else:
    c['change_source'] = changes.SVNPoller(
        svnurl='https://svn.macports.org/repository/macports/trunk',
        #svnbin='/opt/local/bin/svn',
        pollinterval=300,
        category='macports',
        project='ports')


####### SCHEDULERS #######

def change_has_base(change):
    for f in change.files:
        if f.startswith('base'):
            return True
    return False

def change_has_guide(change):
    for f in change.files:
        if f.startswith('doc-new'):
            return True
    return False

def change_has_www(change):
    for f in change.files:
        if f.startswith('www'):
            return True
    return False

base_platforms = [plat for plat in build_platforms if 'legacy' not in plat and '10.6_i386' not in plat]
port_platforms = [plat for plat in build_platforms if 'linux' not in plat and '10.5_ppc' != plat]

base_buildernames = map('base-{}'.format, base_platforms)
portwatcher_buildernames = map('ports-{}-watcher'.format, port_platforms)
portbuilder_buildernames = map('ports-{}-builder'.format, port_platforms)
portbuilder_triggerables = map('ports-{}-trigger'.format, port_platforms)

c['schedulers'] = [
    schedulers.SingleBranchScheduler(
        name='base',
        treeStableTimer=None,
        change_filter=util.ChangeFilter(
            filter_fn=change_has_base),
        builderNames=base_buildernames),
    schedulers.SingleBranchScheduler(
        name='ports',
        treeStableTimer=None,
        change_filter=util.ChangeFilter(
            # Should actually skip changes to files/ only, but only if
            # we know the last build of the port succeeded.
            filter_fn=lambda change: any(port_from_path(f) for f in change.files)),
        builderNames=portwatcher_buildernames),
    schedulers.ForceScheduler(
        name='base_force',
        builderNames=base_buildernames),
#    schedulers.ForceScheduler(
#        name='portbuilder_force',
#        builderNames=portbuilder_buildernames,
#        properties=[util.StringParameter(
#            name='portname',
#            label='Port name:',
#            default='',
#            required=True)
#        ]),
    schedulers.ForceScheduler(
        name='portwatcher_force',
        builderNames=portwatcher_buildernames,
        properties=[util.StringParameter(
            name='portlist',
            label='Port list:',
            default='',
            size=30,
            required=True)])
    ]


if 'www' in config['deploy']:
    c['schedulers'].extend((
        schedulers.SingleBranchScheduler(
            name='www',
            treeStableTimer=300,
            change_filter=util.ChangeFilter(
                filter_fn=change_has_www),
            builderNames=['docs-www']),
        schedulers.ForceScheduler(
            name='www_force',
            builderNames=['docs-www'])
        ))

if 'guide' in config['deploy']:
    c['schedulers'].extend((
        schedulers.SingleBranchScheduler(
            name='guide',
            treeStableTimer=300,
            change_filter=util.ChangeFilter(
                filter_fn=change_has_guide),
            builderNames=['docs-guide']),
        schedulers.ForceScheduler(
            name='guide_force',
            builderNames=['docs-www'])
        ))

for i in range(len(portbuilder_buildernames)):
    c['schedulers'].append(
        schedulers.Triggerable(
            name=portbuilder_triggerables[i],
            builderNames=[portbuilder_buildernames[i]]))


####### BUILDERS #######

# WARNING: mergeRequests has to be False or Triggerable builds will not be scheduled correctly!
c['mergeRequests'] = False

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which slaves can execute them.  Note that any particular build will
# only take place on one slave.

base_factory = util.BuildFactory()
base_factory.workdir = '../build'

#base_factory.addStep(steps.SVN(
#   repourl=util.Interpolate('https://svn.macports.org/repository/macports/%(src::branch:-trunk)s/base'),
base_factory.addStep(steps.SVN(
    repourl='https://svn.macports.org/repository/macports/trunk/base',
    method='copy',
    env={'PATH': path_ports}))
base_factory.addStep(steps.Configure(command=util.WithProperties("""
env PATH=/usr/bin:/bin:/usr/sbin:/sbin ./configure --enable-readline \
    --prefix=%(workdir)s/opt/local \
    --with-applications-dir=%(workdir)s/opt/local/Applications \
    --with-install-user=`id -un` \
    --with-install-group=`id -gn` \
"""),logfiles={'config.log': 'config.log'}))
base_factory.addStep(steps.Compile(command='make -j`sysctl -n hw.activecpu`'))
base_factory.addStep(steps.ShellCommand(
    command='make install',
    name='install',
    description=['installing'],
    descriptionDone=['install']))
base_factory.addStep(steps.ShellCommand(
    command='make test',
    name='test',
    description=['testing'],
    descriptionDone=['test']))
base_factory.addStep(steps.ShellCommand(
    command=util.WithProperties('make distclean; rm -rf %(workdir)s/opt/local'),
    name='clean',
    description=['cleaning'],
    descriptionDone=['clean']))

# custom class to make the file list available on the slave...
class SetPropertyFromCommandWithPortlist(steps.SetPropertyFromCommand):
    def setBuild(self, build):
        super(SetPropertyFromCommandWithPortlist, self).setBuild(build)

        # support forced build properties
        ports = set(self.getProperty('portlist', default='').split())

        # paths should be dports/category/portdir(/...)
        ports.update(ifilter(None, imap(port_from_path, self.build.allFiles())))

        self.setProperty('fullportlist', ' '.join(ports))

    def getText(self, cmd, results):
        if self.hasProperty('subportlist'):
            return ['Port list: {}'.format(self.getProperty('subportlist'))]
        # let ShellCommand describe
        return steps.ShellCommand.getText(self, cmd, results)

# can't run with prefix inside the workdir in production,
# because archives must be built with prefix=/opt/local
if config['production']:
    prefix = '/opt/local'
    dlhost = 'packages@packages-origin.macports.org'
    dlpath = '/var/www/html/packages'
else:
    prefix = config['slaveprefix']
    dlhost = ''
    dlpath = './deployed_archives'

ulpath = 'archive_staging'
ulpath_unique = ulpath+'-%(buildername)s'

@util.renderer
def make_build_url(props):
    buildername = props.getProperty('buildername')
    buildnumber = props.getProperty('buildnumber')
    url = c['buildbotURL']
    if not url.endswith('/'):
        url += '/'
    url += 'builders/%s/builds/%s' % (buildername, buildnumber)
    return url

class TriggerWithPortlist(steps.Trigger):
    def getSchedulersAndProperties(self):
        sp = []
        for scheduler in self.schedulerNames:
            for port in self.build.getProperty('subportlist').split():
                props = self.set_properties.copy()
                props['portname'] = port
                sp.append([scheduler, props])
        return sp


# -- Port Watcher --

def make_portwatcher_factory(triggerable):
    portwatcher_factory = util.BuildFactory()
    portwatcher_factory.useProgress = False
    portwatcher_factory.workdir = '../build'

    # get mp-buildbot; we'll do the checkout of base and dports via these scripts
    portwatcher_factory.addStep(steps.SVN(
        repourl=config['mpbbsvnurl'],
        env={'PATH': path_ports},
        alwaysUseLatest=True,
        preferLastChangedRev=True,
        mode='incremental',
        workdir=os.path.join(portwatcher_factory.workdir, 'mpbb'),
        haltOnFailure=True))

    portwatcher_factory.addStep(steps.ShellCommand(
        command=['./mpbb/mpbb', '--prefix', util.WithProperties(prefix), 'cleanup'],
        name='cleanup',
        description=['cleaning'],
        descriptionDone=['clean']))

    portwatcher_factory.addStep(steps.ShellCommand(
        command=['./mpbb/mpbb', '--prefix', util.WithProperties(prefix), 'selfupdate'],
        name='selfupdate',
        description=['updating', 'MacPorts'],
        descriptionDone=['update', 'MacPorts'],
        haltOnFailure=True))

    portwatcher_factory.addStep(steps.ShellCommand(
        command=['./mpbb/mpbb', '--prefix', util.WithProperties(prefix), 'checkout', '--svn-url', config['svnurl']],
        timeout=3600,
        name='checkout',
        description=['syncing', 'ports'],
        descriptionDone=['sync', 'ports'],
        haltOnFailure=True))

    def extract_subportlist(rc, stdout, stderr):
        """
        Extract function for SetPropertyFromCommand(). Buildbot did not get the
        capability to ignore or distinguish stderr output before 0.9.x, but
        extract_fn always had the option to deal with them separately, so do
        that.

        This is called by SetPropertyFromCommand with the return value of the
        command and strings containing stdout and stderr. The return value
        should be a dictionary of new properties to be set.
        """
        if rc != 0:
            # Set an empty subport list on error
            return {'subportlist': ''}
        subports = [x.strip() for x in stdout.splitlines()]
        return {'subportlist': ' '.join(sorted(subports))}

    portwatcher_factory.addStep(SetPropertyFromCommandWithPortlist(
        command=util.WithProperties('./mpbb/mpbb list-subports %(fullportlist)s'),
        extract_fn=extract_subportlist,
        name='subports',
        description=['listing', 'subports']))

    portwatcher_factory.addStep(TriggerWithPortlist(
        schedulerNames=[triggerable],
        set_properties={'triggered_by': make_build_url},
        waitForFinish=True,
        updateSourceStamp=True))

    # make a logfile summarising the success/failure status for each port
    # (Current approach is not so useful as it is not incremental;
    #  ideally this would already be displayed during the Trigger step.)
    portwatcher_factory.addStep(steps.ShellCommand(
        command=['cat', os.path.join(logdir, 'ports-progress.txt')],
        name='summary',
        description=['summary']))

    return portwatcher_factory

# -- Port Builder --

portbuilder_factory = util.BuildFactory()
portbuilder_factory.useProgress = False
portbuilder_factory.workdir = '../build'
logdir = os.path.join(portbuilder_factory.workdir, 'logs')

portbuilder_factory.addStep(steps.Compile(
    command=['./mpbb/mpbb', '--prefix', util.WithProperties(prefix), 'install-dependencies', util.WithProperties('%(portname)s')],
    name='install-dependencies',
    description=['installing', 'dependencies', 'of', util.WithProperties('%(portname)s')],
    descriptionDone=['install', 'dependencies', 'of', util.WithProperties('%(portname)s')],
    logfiles={'dependencies': os.path.join(logdir, 'dependencies-progress.txt')},
    haltOnFailure=True))

portbuilder_factory.addStep(steps.Compile(
    command=['./mpbb/mpbb', '--prefix', util.WithProperties(prefix), 'install-port', util.WithProperties('%(portname)s')],
    name='install-port',
    description=['installing', util.WithProperties('%(portname)s')],
    descriptionDone=['install', util.WithProperties('%(portname)s')],
    logfiles={'files': os.path.join(logdir, 'port-contents.txt'),
              'statistics': os.path.join(logdir, 'port-statistics.txt'),
              'main.log': os.path.join(logdir, 'main.log')},
    haltOnFailure=True))

portbuilder_factory.addStep(steps.ShellCommand(
    command=['./mpbb/mpbb', '--prefix', util.WithProperties(prefix), 'gather-archives', '--archive-site', config['archivesite'], '--staging-dir', ulpath],
    name='gather-archives',
    description=['gathering', 'archives'],
    descriptionDone=['gather', 'archives'],
    haltOnFailure=True))

# upload archives from build slave to master
portbuilder_factory.addStep(steps.DirectoryUpload(
    slavesrc=ulpath,
    masterdest=util.WithProperties(ulpath_unique)))

# XXX: move deploy_archives.sh functionality to mp-buildbot
# sign generated binaries and sync to download server (if distributable)
if config['production']:
    portbuilder_factory.addStep(steps.MasterShellCommand(
        command=['./deploy_archives.sh', util.WithProperties(ulpath_unique)],
        name='deploy-archives',
        description=['deploying', 'archives'],
        descriptionDone=['deploy', 'archives'],
        env={'PRIVKEY': config['privkey'], 'DLHOST': dlhost, 'DLPATH': dlpath}))

# TODO: do we want to upload the individual logs so maintainers can review them?
portbuilder_factory.addStep(steps.ShellCommand(
    command=['./mpbb/mpbb', '--prefix', util.WithProperties(prefix), 'cleanup'],
    name='cleanup',
    description=['cleaning'],
    descriptionDone=['clean'],
    alwaysRun=True))

def make_rsync_deploy_steps(host, user, sshkeyfile, sshknownhostsfile, srcpath, destpath):
    return (
        steps.FileDownload(
            name='ssh key',
            description='transferring',
            descriptionDone='transfer',
            mastersrc=sshkeyfile,
            slavedest='ssh_key',
            mode=0600),
        steps.FileDownload(
            name='ssh known_hosts',
            description='transferring',
            descriptionDone='transfer',
            mastersrc=sshknownhostsfile,
            slavedest='ssh_known_hosts',
            mode=0600),
        steps.ShellCommand(
            name='rsync',
            description='deploying',
            descriptionDone='deploy',
            command='rsync -avzhC --delay-updates --delete-delay %s/ %s@%s:%s/' % (srcpath, user, host, destpath),
            env={'RSYNC_RSH': 'ssh -i ssh_key -oUserKnownHostsFile=ssh_known_hosts'})
        )

if 'www' in config['deploy']:
    docs_www_factory = util.BuildFactory()
    # TODO: incremental mode with cleanup?
    docs_www_factory.addStep(steps.SVN(
        repourl='https://svn.macports.org/repository/macports/trunk/www',
        mode='full',
        method='copy',
        workdir='www'))
    # TODO: validate/lint files
    docs_www_factory.addSteps(
        make_rsync_deploy_steps(
            host=config['deploy']['www']['host'], 
            user=config['deploy']['www']['user'],
            sshkeyfile=config['deploy']['www']['sshkeyfile'],
            sshknownhostsfile=config['deploy']['www']['sshknownhostsfile'],
            srcpath='www',
            destpath=config['deploy']['www']['destpath']))

if 'guide' in config['deploy']:
    docs_guide_factory = util.BuildFactory()
    # TODO: incremental mode with cleanup?
    docs_guide_factory.addStep(steps.SVN(
        repourl='https://svn.macports.org/repository/macports/trunk/doc-new',
        mode='full',
        method='copy',
        workdir='guide'))
    # TODO: check for existence of tools in toolsprefix
    docs_guide_factory.addStep(steps.Compile(
        name='validate',
        description='validating',
        descriptionDone='validate',
        command='make validate',
        workdir='guide'))
    docs_guide_factory.addStep(steps.Compile(
        command='make all',
        workdir='guide'))
    docs_guide_factory.addSteps(
        make_rsync_deploy_steps(
            host=config['deploy']['guide']['host'], 
            user=config['deploy']['guide']['user'],
            sshkeyfile=config['deploy']['guide']['sshkeyfile'],
            sshknownhostsfile=config['deploy']['guide']['sshknownhostsfile'],
            srcpath='guide',
            destpath=config['deploy']['guide']['destpath']))


####### BUILDER CONFIGURATION #######

# XXX: slavenames assignment should be automatic and more generic
portsslaves = {}
baseslaves = {}
slavenames = slavedata['slaves'].keys()
for plat in build_platforms:
    baseslaves[plat]  = filter(lambda x: x.endswith(plat+'-base'),  slavenames)
    portsslaves[plat] = filter(lambda x: x.endswith(plat+'-ports'), slavenames)

env_buildinfo = {
    'BUILDBOT_BUILDERNAME': util.WithProperties('%(buildername)s'),
    'BUILDBOT_BUILDNUMBER': util.WithProperties('%(buildnumber)s'),
    'BUILDBOT_BUILDURL': make_build_url
    }

c['builders'] = []
extract_os = re.compile(r'10\.\d+')
for plat in build_platforms:
    os_match = extract_os.search(plat)
    os_version = os_match.group(0) if os_match else plat
    if 'legacy' not in plat and '10.6_i386' not in plat:
        c['builders'].append(
            util.BuilderConfig(
                name='base-' + plat,
                slavenames=['base-' + plat],
                factory=base_factory,
                tags=['base', os_version],
                env=merge_dicts(env_buildinfo, {'PATH': path_base})))
    if 'linux' not in plat and '10.5_ppc' != plat:
        c['builders'].extend((
            util.BuilderConfig(
                name='ports-' + plat + '-watcher',
                slavenames=['ports-' + plat],
                factory=make_portwatcher_factory('ports-' + plat + '-trigger'),
                tags=['portwatcher', os_version],
                env=merge_dicts(env_buildinfo, {'PATH': path_ports})),
            util.BuilderConfig(
                name='ports-' + plat + '-builder',
                slavenames=['ports-' + plat],
                factory=portbuilder_factory,
                tags=['portbuilder', os_version],
                env=merge_dicts(env_buildinfo, {'PATH': path_ports}))
            ))

if 'www' in config['deploy']:
    c['builders'].append(
        util.BuilderConfig(
            name='docs-www',
            slavenames=['docs'],
            factory=docs_www_factory,
            tags=['docs', 'www'],
            env=merge_dicts(env_buildinfo, {'PATH': path_ports})))
if 'guide' in config['deploy']:
    c['builders'].append(
        util.BuilderConfig(
            name='docs-guide',
            slavenames=['docs'],
            factory=docs_guide_factory,
            tags=['docs', 'guide'],
            env=merge_dicts(env_buildinfo, {'PATH': path_ports})))


####### STATUS TARGETS #######

# 'status' is a list of Status Targets. The results of each build will be
# pushed to these targets. buildbot/status/*.py has a variety to choose from,
# including web pages, email senders, and IRC bots.

c['status'] = []

htauth = util.HTPasswdAprAuth(config['htpasswdfile'])

authz_cfg = util.Authz(
    auth=htauth,
    gracefulShutdown='auth',
    forceBuild='auth',
    forceAllBuilds='auth',
    pingBuilder='auth',
    stopBuild='auth',
    stopAllBuilds='auth',
    cancelPendingBuild='auth')

# TODO: This is the old mail notifier;
# - useful functionality could be copied
# - then the code should be removed
#
# notifier that sends mail to last committers and maintainers of failed ports
class OldPortsMailNotifier(status.MailNotifier):
    # would make more sense to override getInterestedUsers() in BuildStatus,
    # but it seems almost impossible to tell a builder to use a different
    # class for status in its Build objects
    def useLookup(self, build):
        failedPorts = set()
        interestedUsers = set()

        # XXX: needs to be rewritten for the new steps of mp-buildbot
        statusStep = [x for x in build.getSteps() if x.getName() == 'status'][0]
        statusLog = [x for x in statusStep.getLogs() if x.getName() == 'portstatus'][0]
        for line in statusLog.getText().splitlines():
            halves = line.split()
            if halves[0] == '[FAIL]':
                failedPorts.add(halves[1])
        
        fakeAddresses = {'nomaintainer', 'nomaintainer@macports.org', 'openmaintainer', 'openmaintainer@macports.org'}
        for p in failedPorts:
            output = subprocess.Popen(['/opt/local/bin/port', 'info', '--index', '--maintainers', '--line', p], stdout=subprocess.PIPE).communicate()[0].strip()
            for m in output.split(','):
                if m not in fakeAddresses:
                    interestedUsers.add(m)

        ss = build.getSourceStamp()
        if ss:
            for c in ss.changes:
                interesting = False
                for f in c.files:
                    comps = f.split('/')
                    if len(comps) >= 3 and comps[2] in failedPorts and comps[0] == 'dports' and comps[1] != '_resources':
                        interesting = True
                        break
                if interesting:
                    interestedUsers.add(c.who)

        dl = []
        for u in interestedUsers:
            d = defer.maybeDeferred(self.lookup.getAddress, u)
            dl.append(d)
        return defer.gatherResults(dl)

class PortsMailNotifier(status.MailNotifier, object):
    def __init__(self, fromaddr, *args, **kwargs):
        self.interested_users = set()
        self.portMessageFormatter = kwargs.pop('portMessageFormatter')
        super(PortsMailNotifier, self).__init__(fromaddr=fromaddr, *args, **kwargs)

    # same as original, but calls portMessageFormatter with access to interested_users
    def buildMessageDict(self, name, build, results):
        self.interested_users.clear()
        msgdict = self.portMessageFormatter(
            self.mode, name, build, results, self.master_status, self.interested_users)
        return msgdict

    def useLookup(self, build):
        dl = []

        # add additional recipients
        for u in self.interested_users:
            d = defer.maybeDeferred(self.lookup.getAddress, u)
            dl.append(d)

        # original list of recipients
#        for u in build.getResponsibleUsers() + build.getInterestedUsers():
#            d = defer.maybeDeferred(self.lookup.getAddress, u)
#            dl.append(d)
        return defer.gatherResults(dl)

def portWatcherMessageFormatter(mode, name, build, results, master_status, interested_users):
    result = util.Results[results]
    subject = 'Build {:s}'.format(result.title())
    text = list()
    text.append('Status:       {:s}'.format(result.title()))
    text.append('Build slave:  {:s}'.format(build.getSlavename()))
    if master_status.getURLForThing(build):
        text.append('Full logs:    {:s}'.format(master_status.getURLForThing(build)))
        text.append('Build reason: {:s}'.format(build.getReason()))
        text.append('Port list:    {:s}'.format(build.getProperty('fullportlist')))
        text.append('Subport list:\n\t- {:s}'.format(build.getProperty('subportlist').replace(' ', '\n\t- ')))
        text.append('Variants:     {:s}'.format(build.getProperty('variants')))
        text.append('Revision:     {:s}'.format(build.getProperty('revision')))
        text.append('Build time:   {:s}'.format(datetime.timedelta(seconds=int(round(build.getTimes()[1] - build.getTimes()[0])))))
        text.append(u'Committer:    {:s}'.format(','.join(build.getResponsibleUsers())))

        text.append('\nLog from failed builds:')
        summary_step = [x for x in build.getSteps() if x.getName() == 'summary'][0]
        summary_log  = [x for x in summary_step.getLogs() if x.getName() == 'stdio'][0]
        failed_ports = set()
        maintainers_to_notify = set()
        pattern = re.compile(r"^Building '(?P<port>.*?)'.*?(\(failed to install dependency '(?P<dependency>.*?)'\))?( maintainers: (?P<maintainers>.*?)[.])?$")
        # iterate through all the ports being built
        for line in summary_log.getText().splitlines():
            # in case of a build error, print the error and add the broken port(s) to the list
            if 'ERROR' in line:
                line = line.replace(';', '@')
                text.append('\t' + line.replace(' maintainers:', '\n\t> maintainers:'))
                match = pattern.match(line)
                if match:
                    for key in ['port', 'dependency']:
                        port = match.groupdict().get(key)
                        if port:
                            failed_ports.add(port)
                    maintainers = match.groupdict().get('maintainers')
                    if maintainers:
                        for maintainer in maintainers.split(','):
                            maintainers_to_notify.add(maintainer)
        if len(failed_ports) > 0:
            text.append('\nBroken ports:\n\t- {:s}'.format('\n\t- '.join(sorted(failed_ports))))

        if len(maintainers_to_notify) > 0:
            text.append('\nResponsible maintainers:\n\t- {}'.format('\n\t- '.join(sorted(maintainers_to_notify))))
            for user in maintainers_to_notify:
                interested_users.add(user)

        # links to individual builds
        text.append('\nLinks to individual build jobs:')
        trigger_step = [x for x in build.getSteps() if x.getName() == 'trigger'][0]
        build_urls_dict = trigger_step.getURLs()
        # TODO; sorting won't work properly for
        # - ports-10.11-x86_64-builder #99
        # - ports-10.11-x86_64-builder #100
        build_urls_keys = sorted(build_urls_dict.keys())
        for k in build_urls_keys:
            text.append('- {:s}\n  {:s}'.format(k, build_urls_dict[k]))
        text.append('\n-- \nBest regards,\nMacPorts Buildbot\n{:s}'.format(c['buildbotURL']))

        if failed_ports:
            subject += ': '
            subject += ', '.join(sorted(failed_ports)[:10])
            if len(failed_ports) > 10:
                subject +=  ', and {} more'.format(len(failed_ports) - 10)
    return {'body': '\n'.join(text), 'type': 'plain', 'subject': subject}

if config['production']:
    # send mail about base failures to users on the blamelist
    mn = status.MailNotifier(
        fromaddr='buildbot@macports.org',
        extraHeaders={'Reply-To': 'noreply@macports.org'},
        # unless lookup is defined, users have to be configured locally
        # maybe a smarter function is needed, but lookup='' does it for now
        lookup='',
        mode=('problem'),
        builders=base_buildernames,
        #extraRecipients=['...'],
        #smtpPort=25,
        #relayhost='localhost',
        sendToInterestedUsers=True)
    c['status'].append(mn)

    mn = PortsMailNotifier(
        fromaddr='buildbot@macports.org',
        extraHeaders={'Reply-To': 'noreply@macports.org'},
        lookup='',
        mode=('failing'),
        builders=portwatcher_buildernames,
        #extraRecipients=['...'],
        #smtpPort=25,
        #relayhost='localhost',
        sendToInterestedUsers=True,
        portMessageFormatter=portWatcherMessageFormatter)
    c['status'].append(mn)

    # notifications about exceptions
    mn = status.MailNotifier(
        fromaddr='buildbot@macports.org',
        extraHeaders={'Reply-To': 'noreply@macports.org'},
        mode=('exception'),
        extraRecipients=['admin@macports.org'],
        sendToInterestedUsers=False)
    c['status'].append(mn)

####### PROJECT IDENTITY #######

# the 'title' string will appear at the top of this buildbot
# installation's WebStatus home page (linked to the
# 'titleURL') and is embedded in the title of the waterfall HTML page.

c['title'] = 'MacPorts'
c['titleURL'] = 'https://www.macports.org/'

c['buildbotURL'] = config['buildboturl']
c['status'].append(WebStatus(
    http_port=config['httpport'],
    authz=authz_cfg,
    changecommentlink=(r'#(\d+)', r'https://trac.macports.org/ticket/\1', r'Ticket \g<0>')))

c['revlink'] = util.RevlinkMatch([r'https://svn.macports.org/repository/macports/(.*)'],
                                  r'https://trac.macports.org/changeset/%s')


####### DATABASE #######

# This specifies what database buildbot uses to store its state. You can
# leave this at its default for all but the largest installations.
c['db'] = {'db_url': 'sqlite:///state.sqlite'}


####### DATA LIFETIME #######
c['buildHorizon'] = 10000
c['logHorizon'] = 5000
c['eventHorizon'] = 2000
c['buildCacheSize'] = 600
